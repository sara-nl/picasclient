{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db16787b",
   "metadata": {},
   "source": [
    "\n",
    "# Use PiCaS to run tasks on Snellius\n",
    "\n",
    "## Outline\n",
    "- Set up a non trivial example - the fractals example\n",
    "- Create tokens and push them to the database\n",
    "- Run the tasks on Snellius using PiCaS by pulling tokens from the database\n",
    "\n",
    "## references\n",
    "- 02-local-run.ipynb notebook\n",
    "\n",
    "## Minimum requirements\n",
    "- you have run the 02-local-run.ipynb notebook and have a working PiCaS database\n",
    "- you have access to Snellius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24dca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/picas\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3760f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir example_04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbdee73",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## First we need to define / create the tokens for the Fractals example.\n",
    "The \"create_tokens\" script creates tokens and puts them in a temporary file\n",
    "The expected content of the file are similar to the following:\n",
    "\n",
    "  ```\n",
    "  -q 0.100 -d 256 -m 400\n",
    "  -q 0.100 -d 256 -m 4400\n",
    "  -q 0.100 -d 256 -m 8400\n",
    "  -q 0.100 -d 2280 -m 400\n",
    "  -q 0.100 -d 2280 -m 4400\n",
    "  -q 0.100 -d 2280 -m 8400\n",
    "  -q 0.100 -d 4304 -m 400\n",
    "  ```\n",
    "These are parameters that will be passed to the executable that will be run for each token.\n",
    "(just for eyeballing purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d911fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd examples\n",
    "! ./create_tokens\n",
    "\n",
    "# check the content of the created tokens file that is created (last file in ls -ltr)\n",
    "! ls -ltr /tmp | tail -n 1 | awk '{print $9}' | xargs -I {} cat /tmp/{}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e823e312",
   "metadata": {},
   "source": [
    "Next we need to push the tokens to the database, we reuse the create_token function for\n",
    "the 02 example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd5677",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import picasconfig\n",
    "from picas.clients import CouchDB\n",
    "from picas.documents import Task\n",
    "\n",
    "def create_tokens(fields: dict) -> list:\n",
    "    \"\"\"\n",
    "    Create the tokens as a list of Task documents.\n",
    "\n",
    "    The fields parameter is a dictionary where keys are field names and values are\n",
    "    lists of input values. For every 'input' value a unique id is assigned and the\n",
    "    corresponding input value is used to create a token.\n",
    "\n",
    "    For example, the following becomes a list of tokens:\n",
    "     {'input': [\n",
    "        \"echo 'this is token A'\",\n",
    "        \"echo 'this is token B'\",\n",
    "        \"echo 'this is token C'\"]\n",
    "     }\n",
    "\n",
    "\n",
    "    :param fields: A dictionary where keys are field names and values are lists of input values.\n",
    "    :return: A list of Task documents representing the tokens. For the example above,\n",
    "      it would return a list of three Task objects with .id attributes set to\n",
    "      'token_0', 'token_1', and 'token_2' respectively and .input attributes of each set to\n",
    "      \"echo 'this is token A'\", \"echo 'this is token B'\", and \"echo 'this is token C'\".\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    n_docs = db.doc_count()\n",
    "    for arg in fields:\n",
    "        for line in fields[arg]:\n",
    "            token = {\n",
    "                '_id': 'token_' + str(n_docs),\n",
    "                'type': 'token',\n",
    "                arg: line,\n",
    "            }\n",
    "            tokens.append(Task(token))\n",
    "            n_docs += 1\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6033a",
   "metadata": {},
   "source": [
    "read the tokens from the file in /tmp and push them to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokensfile = subprocess.check_output(\"./createTokens\", text=True).rstrip('\\n')\n",
    "with open(tokensfile) as fobj:\n",
    "    fields = {\"input\": fobj.read().splitlines()}\n",
    "    tokens = create_tokens(fields)\n",
    "\n",
    "# create a connection to the server\n",
    "db = CouchDB(\n",
    "    url=picasconfig.PICAS_HOST_URL,\n",
    "    db=picasconfig.PICAS_DATABASE,\n",
    "    username=picasconfig.PICAS_USERNAME,\n",
    "    password=picasconfig.PICAS_PASSWORD)\n",
    "\n",
    "\n",
    "# save tokens in database\n",
    "db.save_documents(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3993d1",
   "metadata": {},
   "source": [
    "Compile and build the executable that runs the non trivial fractals code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6e58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cc src/fractals.c -o bin/fractals -lm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad808e5",
   "metadata": {},
   "source": [
    "### The script that runs a fractals task: process_task.sh\n",
    "The script basically accepts the tokens as input command line parameters.\n",
    "The following is done in the script:\n",
    " - display the node name and date\n",
    " - initialize the job arguments and echo them (for verbosity)\n",
    " - for the sake of demonstration, run the input command as a bash command\n",
    " - wrap up the job by displaying the end date and exit code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile example_04/process_task.sh\n",
    "#!/bin/bash\n",
    "\n",
    "# usage\n",
    "#  ./process_task.sh <input_command> <token_id>\n",
    "#  ./process_task.sh 'sleep 1' my_token_id\n",
    "# enable verbosity\n",
    "#set -x\n",
    "\n",
    "# obtain/dump the information for the Worker Node to stdout\n",
    "echo \"\"\n",
    "echo `date`\n",
    "echo ${HOSTNAME}\n",
    "\n",
    "# initialize job arguments\n",
    "INPUT_CMD=$1\n",
    "TOKENID=$2\n",
    "OUTPUT=output_${TOKENID}\n",
    "echo \"----------- input argument ----------------\"\n",
    "echo \"Input command: ${INPUT_CMD}\"\n",
    "echo \"Token ID: ${TOKENID}\"\n",
    "echo \"Output file: ${OUTPUT}\"\n",
    "echo \"------------ end input argument ---------------\"\n",
    "\n",
    "#\n",
    "# start processing\n",
    "#\n",
    "\n",
    "# short example, just echo the input\n",
    "# use this command for the short example, replace this with something else\n",
    "# that does fancy things for a real life application\n",
    "# .. just run something, dummy task\n",
    "echo \"----------------- start execute task --------------------------------\"\n",
    "bin/fractals -o $OUTPUT $INPUT\n",
    "echo \"----------------- end execute task --------------------------------\"\n",
    "\n",
    "# display the end date\n",
    "echo `date`\n",
    "\n",
    "exit 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d97a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the execute permission on the script\n",
    "! chmod +x example_04/process_task.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1017d",
   "metadata": {},
   "source": [
    "## Create the job script that will allocate the pilot job and run the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194e738",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%writefile example_04/slurm_example.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --array=0-5\n",
    "#SBATCH -t 00:30:00\n",
    "#SBATCH -p rome\n",
    "\n",
    "#how to use this example:\n",
    "#1.clone the Picasclient github\n",
    "#git clone https://github.com/sara-nl/picasclient.git\n",
    "#cd picasclient\n",
    "#2.install packages\n",
    "#pip install picas\n",
    "#3.create examples/picasconfig.py using template picasconfig_example.py\n",
    "#4.submit pilot job\n",
    "#sbatch snellius-example.sh\n",
    "#ALERT: The minimal allocation on Snellius is 16 cores.\n",
    "\n",
    "\n",
    "## adding software modules load for Snellius\n",
    "module load 2024\n",
    "module load Python/3.12.3-GCCcore-13.3.0\n",
    "pip install --user picas\n",
    "\n",
    "\n",
    "# You may set environmental variables needed in the SLURM job\n",
    "# For example, when using the LUMI container wrapper:\n",
    "# export PATH=\"/path/to/install_dir/bin:$PATH\"\n",
    "python local_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d48b7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Use the existing local_example.py script to run the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile example_04/local_example.py\n",
    "\"\"\"\n",
    "usage: python local_example.py\n",
    "description:\n",
    "    Connect to PiCaS server\n",
    "    Get the next token in todo View\n",
    "    Fetch the token parameters, e.g. input value\n",
    "    Run main job (process_task.sh) with the input argument\n",
    "    When done, return the exit code to the token\n",
    "    Attach the logs to the token\n",
    "\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import picasconfig\n",
    "\n",
    "from picas.actors import RunActor\n",
    "from picas.clients import CouchDB\n",
    "from picas.executers import execute\n",
    "from picas.modifiers import BasicTokenModifier\n",
    "from picas.util import Timer\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def arg_parser():\n",
    "    \"\"\"\n",
    "    Arguments parser for optional values of the example\n",
    "    returns: argparse object\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Arguments used in the different classes in the example.\")\n",
    "    parser.add_argument(\"--design_doc\", default=\"Monitor\", type=str, help=\"Select the designdoc used by the actor class\")\n",
    "    parser.add_argument(\"--view\", default=\"todo\", type=str, help=\"Select the view used by the actor class\")\n",
    "    parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\", help=\"Set verbose\")\n",
    "    return parser\n",
    "\n",
    "class ExampleActor(RunActor):\n",
    "    \"\"\"\n",
    "    The ExampleActor is the custom implementation of a RunActor that the user needs for the processing.\n",
    "    Feel free to adjust to whatever you need, a template can be found at: example-template.py\n",
    "    \"\"\"\n",
    "    def __init__(self, db, modifier, view=\"todo\", **viewargs):\n",
    "        super(ExampleActor, self).__init__(db, view=view, **viewargs)\n",
    "        self.timer = Timer()\n",
    "        # self.iterator = EndlessViewIterator(self.iterator)\n",
    "        self.modifier = modifier\n",
    "        self.client = db\n",
    "\n",
    "    def process_task(self, token):\n",
    "        # Print token information\n",
    "        print(\"-----------------------\")\n",
    "        print(\"Working on token: \" +token['_id'])\n",
    "        for key, value in token.doc.items():\n",
    "            print(key, value)\n",
    "        print(\"-----------------------\")\n",
    "\n",
    "        # Start running the main job, the logging is done internally and saved below\n",
    "        command = [\"/usr/bin/time\", \"./process_task.sh\", token['input'], token['_id']]\n",
    "        out = execute(command)\n",
    "\n",
    "        logsout = f\"logs_{token['_id']}.out\"\n",
    "        logserr = f\"logs_{token['_id']}.err\"\n",
    "\n",
    "        # write the logs\n",
    "        with open(logsout, 'w') as f:\n",
    "            f.write(out[2].decode('utf-8'))\n",
    "        with open(logserr, 'w') as f:\n",
    "            f.write(out[3].decode('utf-8'))\n",
    "\n",
    "        self.subprocess = out[0]\n",
    "\n",
    "        # Get the job exit code and done in the token\n",
    "        token['exit_code'] = out[1]\n",
    "        token = self.modifier.close(token)\n",
    "\n",
    "        # Attach logs in token\n",
    "        curdate = time.strftime(\"%d/%m/%Y_%H:%M:%S_\")\n",
    "        try:\n",
    "            log_handle = open(logsout, 'rb')\n",
    "            token.put_attachment(logsout, log_handle.read())\n",
    "\n",
    "            log_handle = open(logserr, 'rb')\n",
    "            token.put_attachment(logserr, log_handle.read())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "def main():\n",
    "    # parse user arguments\n",
    "    args = arg_parser().parse_args()\n",
    "\n",
    "    # setup connection to db\n",
    "    client = CouchDB(\n",
    "        url=picasconfig.PICAS_HOST_URL,\n",
    "        db=picasconfig.PICAS_DATABASE,\n",
    "        username=picasconfig.PICAS_USERNAME,\n",
    "        password=picasconfig.PICAS_PASSWORD)\n",
    "    print(\"Connected to the database %s sucessfully. Now starting work...\" %(picasconfig.PICAS_DATABASE))\n",
    "\n",
    "    # create the token modifier\n",
    "    modifier = BasicTokenModifier()\n",
    "\n",
    "    # create the actor\n",
    "    actor = ExampleActor(client, modifier, view=args.view, design_doc=args.design_doc)\n",
    "\n",
    "    # start the work!\n",
    "    actor.run(max_token_time=1800, max_total_time=3600, max_tasks=10, max_scrub=2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e08c8d",
   "metadata": {},
   "source": [
    "Now you can submit the job to Snellius with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dceba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd example_04 && sbatch slurm_example.sh"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
